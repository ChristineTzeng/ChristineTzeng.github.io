---
layout: default
---
<html>
<head>
  <title>Sz-Ting "Christine" Tzeng's Ph.D. Defense</title>
</head>

<body>
  <h1>Understanding the Interplay of Social Signals and Values in Norm Emergence</h1>
  <blockquote>
    <h3> Exam Details </h3>
    <ul>
      <li>Defender: Sz-Ting (Christine) Tzeng</li>
      <li>Advisor: Munindar P. Singh</li>
      <li>Unconditionally passed on: August 2nd, 2023, 2:00PM - 4:00PM on Zoom</li>
    </ul>
    <h3> Committee </h3>
    <ul>
      <li>Chair: <a href="https://www.csc2.ncsu.edu/faculty/mpsingh/">Dr. Munindar P. Singh</a></li>
      <li>Member: <a href="https://facultyclusters.ncsu.edu/people/ahjhala/">Dr. Arnav Jhala</a></li>
      <li>Member: <a href="https://www.csc.ncsu.edu/people/mchi">Dr. Min Chi</a></li>
      <li>Member: <a href="https://poole.ncsu.edu/people/wmrand/">Dr. William Rand (GSR)</a></li>
      <li>External Member: <a href="https://niravajmeri.github.io/">Dr. Nirav Ajmeri</a></li>
    </ul>
    <h3> Abstract: </h3>
    <p>
      Advancements in technology have seamlessly integrated Artificial Intelligence (AI) into our daily lives.
      Software engages in dynamic interactions with its environment, other software, and human beings, fostering a symbiotic relationship. 
      The interconnectedness gives rise to a multiagent system (MAS) where humans and AI work together in synergy to attain shared objectives.
      Given the involvement of humans, AI systems must be able to reason over human behaviors, which are determined by a combination of internal attitudes and external factors.
      Incorporating human values and considering multiagent dynamics in decision-making would lead to a substantial improvement in the reliability and realism of AI systems.
      Besides aligning decisions with values, humans have a fundamental need to comprehend and place trust in the output of AI.
      <br>
      Another concern that arises from the growing size and dynamics of the MAS is adaptability.
      Social norms define acceptable group conduct and governing agent behaviors in MAS.
      Norms can arise through top-down imposition or bottom-up emergence.
      In both approaches, norms and the environment are subject to change over time.
      The capacity for adaptation in AI systems becomes crucial to minimize human intervention and effort in maintaining MAS.
      <br>
      In this dissertation, we aim to incorporate adaptability and explainability in AI systems by integrating normative MAS with human factors.
      Initially, we concentrate on elements that help to regulate human behaviors.
      Subsequently, we explore human factors associated with human needs.
      This research includes four components: emotions as sanctions, normative information from social signals, social value orientation, and value-aligned rationale.
    </p>
    
    <h3> Approaches: </h3>
    <p>
      In this dissertation, we propose 
      <ul>
        <li>(1) Noe, a framework that models the emotional responses of agents to the outcomes of interactions. 
            Emotions, which are responses to internal or external events, can act as a positive or negative reinforcement mechanism for specific behaviors. 
        </li>
        <li>(2) Hermione, a framework that incorporates normative information from social signals to support norm emergence.
            In addition to sanctions, normative information from soft signals like hints and messages helps to regulate behaviors.
        </li>
        <li>(3) Fleur, a framework that incorporates the social value orientation concept. 
            Social value orientation defines individuals' preferences over resource allocations between themselves and others.
            Aligning with social values enables AI to make ethical decisions and be responsible for human needs.
        </li>
        <li>(4) Exanna, a framework that makes decisions and reveals information in rationales based on agents' value. 
            Value-aligned explanations ensure the AI system's decisions are consistent with human values and societal expectations.
        </li>
    </ul>
  </p>
  </blockquote>
  
  
  
  <h2> Document </h2>
  <ul>
    <li><a href="dissertation/HumanCentricityandNormAwarenessinCognitiveSystemsV1_1.pdf">Version 1.1 (July 19, 2023)</a></li>
    <li><a href="dissertation/HumanCentricityandNormAwarenessinCognitiveSystemsV1_2.pdf">Version 1.2 (July 22, 2023)</a></li>
    <li><a href="dissertation/UnderstandingtheInterplayofSocialSignalsandValuesinNormEmergenceV2">Version 2 (September 5, 2023)</a></li>
  </ul>

<!--   <h2> Publications </h2> -->
  
</body>

</html>
